[TOC]



# 第四章 存储器管理

**当前OS中，普遍采用基于离散分配方式的分页和分段机制的虚拟内存机制**



## 4.1 存储器的层次结构



### 4.1.1 多层结构的存储器系统

1. 目的：
   * 为了缓和存储器要求速度快、容量大、价格低的根本矛盾；
   * 缓和高性能与低价格的矛盾；
2. 典型结构：
   * 三层结构：寄存器、主存(内存)、辅存(外存)
   * 六层结构：寄存器、高速缓存、主存、磁盘缓存、固定磁盘、可移动存储介质
3. 特点：层次越高(越靠近CPU)，访问速度越快，容量越小，价格越高；
4. 分类：
   * 可执行存储器：
     * 包含：寄存器、高速缓存、主存、磁盘缓存
     * 特点：
       - 属于存储管理的范畴；
       - 通过CPU指令访问，访问时间短；
   * 辅存：
     * 包含：固定磁盘、可移动存储介质
     * 特点：
       * 属于设备管理的范畴；
       * 通过I/O设备访问，访问时间长；



### 4.1.2 主存与寄存器

1. 主存：

   * 作用：保存进程运行时的程序和数据；

     ​	(通常处理机都是从主存中取得指令和数据，将其放入寄存器中，或反之。)

   * 特点：访问速度远低于CPU执行指令的速度；

2. 寄存器：

   * 作用：存放CPU即将执行的指令和数据；
   * 特点：速度快，完全能与CPU协调工作；价格昂贵；容量小；



### 4.1.3 高速缓存与磁盘缓存

1. 高速缓存(Cache)：

   * 目的：介于寄存器与主存之间，缓和主存与处理机之间访问速度相差过大的矛盾；

   * 作用：备份主存中常用的数据，减少处理机对主存的访问，从而提高速度；

   * 将主存中的常用数据放在高速缓存中是否有效？

     * **局部性原理：程序在执行时将呈现局部性规律，即在一较短的时间内，程序的执行仅限于某个部分；**
         * 时间局限性：如果程序中的某条指令被执行，不久后该指令可能再次被执行；如果某数据被访问，不久后该数据可能再次被访问；
         * 空间局限性：一旦程序访问了某个存储单元，在不久以后，其附近的存储单元也将被访问；
     
   * **有关cache的几个重要概念：**

       * cache命中：

           * CPU请求的数据在cache中存在；(L3Cache的命中率为95%，只有5%的数据需要从内存中读取)

       * cache行：(cache line)

           * cache与内存交换数据时，是以cache行为单位的，一个cache行一般是64个字节；

       * cache bouncing：

           * 当很多线程频繁修改某个字段时，这个字段所在的cache line被不停的同步到不同的核上，就像在核间弹来弹去，这个现象叫cache bouncing；

       * cache一致性：

           * 在多核处理器中，每个CPU有自己私有的L1,L2cache，若其中一个CPU修改了自己L1cache中的数据，而其他CPUL1cache和主存中对应的数据没有被修改，就造成了共享数据的不一致；

           * cache一致性即指的是多个CPU cache之间缓存的共享数据的一致；

           * 为保证cache一致性，有诸多缓存一致性协议，其中MESI协议使用最为广泛；

               (M:modified; E:exclusive; S:shared; I:invalid)

       * cache伪共享：(cache false sharing)

           * 缓存系统中是以缓存行(cache line)为单位存储和交换信息的，当多线程修改相互独立的变量时，如果这些变量在同一个缓存行上，就会无意中影响彼此的性能，这就叫cache伪共享；
           * cache伪共享：并发编程无声的性能杀手；
           * 如何解决：(实际开发中难以发现和解决)
               * 让不同的线程操作不同的缓存行；(缓存行填充)
               * 使用编译指示，强制让每个变量对齐；

2. 磁盘缓存：(swap分区)

   * 目的：缓和磁盘的I/O速度远低于主存访问速度的矛盾；

   * 作用：暂时存放频繁使用的一部分磁盘数据和信息，以减小磁盘的访问次数；

   * 与高速缓存的不同：

     * 磁盘缓存本身并不是一种实际存在的存储器，而是利用主存中的部分存储空间暂时存放从磁盘中读出来(或写入)的信息。



## 4.2 程序的装入和链接

### 4.2.1 程序的装入(单个目标模块如何装入)

​	(无需进行链接的单个目标模块的装入过程，目标模块就是装入模块)

1. 绝对装入方式(Absolute Loading Mode)【适用于单道程序环境】

   * 方法：用户程序在编译后，将产生绝对地址(即物理地址)的目标代码；
   * 特点：程序中的相对地址(即逻辑地址)与实际内存地址完全相同，不需要修改程序和数据的地址；

2. 可重定位装入方式(Relocation Loading Mode)【可用于多道程序环境】

   * 方法：根据内存的具体情况，将装入模块装入到内存的适当位置；
   * 特点：装入内存后，装入模块的逻辑地址与物理地址不同，需要修改；
     * 把在装入时对目标程序中指令和数据地址的修改过程称为重定位；
     * 因为地址变换通常是在装入时一次完成的，以后不再改变，故称为静态重定位；

3. 动态运行时装入方式(Dynamic Run-time Loading)

   * 问题：重定位装入方式不允许程序运行时在内存中移动位置，而实际中通常需要移动位置。(eg : 对换)

   * 方法：把装入模块装入到内存后，并不立即把模块中的逻辑地址转换为物理地址，而是把这种地址转换推迟到程序真正要执行时才进行；

     (为使地址转换不影响指令的执行速度，这种方式需要一个重地位寄存器的支持)



### 4.2.2 程序的链接(多个目标模块如何装入并链接)

​	**链接程序：将所有的目标模块以及所需的库函数链接成一个完整的装入模块。**

​	根据链接时间的不同，分为三类：

1. 静态链接(Static Linking)
   * 做法：在程序运行前，先将各目标模块以及所需库函数链接成一个完整的装配模块，以后不再拆开。
   * 须解决的问题：
     * 对相对地址进行修改；
     * 变换外部调用符号；(将模块中所用的外部调用符号也都变换为相对地址)
2. 装入时动态链接(Load-time Dynamic Linking)
   * 做法：将目标模块装入内存时，采用边装入边链接的链接方式(即发生模块调用时，才装入被调用模块)。
   * 优点：
     * 便于修改和更新(静态链接时不方便修改)；
     * 便于实现对目标模块的共享；
3. 运行时动态链接(Run-time Dynamic Linking)
   * 问题：有些目标模块可能根本就不运行(eg : 作为错误处理用的目标模块)
   * 做法：对模块的链接推迟到程序执行时才进行
   * 优点：加快程序的装入过程；节省大量内存空间；

(Note : C++内联函数属于静态链接，函数调用属于动态链接？)



## 4.3 连续分配存储

1. 定义：连续分配存储，为用户程序分配一个连续的内存空间，即程序中代码或数据的逻辑地址相邻，体现在内存空间分配时物理地址的相邻。
2. 分类：
   * 单一连续分配
   * 固定分区分配
   * 动态分区分配
   * 动态可重定位分区分配



### 4.3.1 单一连续分配

1. 做法：在单道程序系统中，把内存分为系统区和用户区两部分。系统区仅提供给OS使用，通常存放在内存的低址部分；在用户区内存中(高址部分)，仅装有一道用户程序。



### 4.3.2 固定分区分配

1. 目的：多道程序系统中，为了能在内存中装入多道程序，且使这些程序之间又不会发生干扰；
2. 做法：将整个用户空间划分为若干个固定大小的区域，在每个分区中只装入一道作业；
3. 划分分区的方法：
   * 分区大小相等：缺乏灵活性
   * 分区大小不等：增加了灵活性
4. 内存分配：
   * 通常将分区按其大小排队，并为之建立一张分区使用表(包含各分区起始地址、大小、状态)；
   * 当有用户程序要装入时，按照用户程序的大小检索该表，找到能满足要求且未分配的分区，分配给该程序。若未找到，则拒绝为该程序分配内存；
5. 缺点：每个分区大小固定，必然造成了存储空间的浪费；



### 4.3.3 动态分区分配

1. 做法：根据进程的实际需要，动态地为之分配内存空间；

2. 动态分区分配中的数据结构：

   * 作用：用于描述空闲分区和已分配分区的情况，为分配提供依据；

   * 两种形式：

     * 空闲分区表：

       每个空闲分区占一个表目，表目中包括分区号、分区大小、分区起始地址、分区状态等数据项；

     * 空闲分区链：

       为了实现对空闲分区的分配和链接，在分区的首位部分设置一些用于控制分区分配的信息，以及用于链接各分区的指针，将所有的空闲分区链接成一个双向链；

3. 动态分区分配算法

   * 基于**顺序搜索**的动态分区分配算法：
     * 首次适应算法(First Fit, FF)
       * 要求：空闲分区链以地址递增的次序链接；
       * 做法：从链首开始顺序查找，直到找到一个大小能满足要求的空闲分区为止；
       * 优点：
         * 优先利用内存中的低址部分的空闲空间，保留了高址部分的大空闲区，为以后到达的大作业提供了内存条件；
       * 缺点：
         * 低址部分被不断划分，留下很多难以利用的、很小的空闲分区，称为碎片；
         * 每次搜索都从低址部分开始，会增加查找可用空闲分区的开销；
     * 循环首次适应算法(Next Fit, NF)
       * 做法：
         * 每次不再从链首开始查找，而是从上次找到的空闲分区的下一个空闲分区开始查找，直至找到一个能满足要求的空闲分区；
         * 如果最后一个空闲分区(链尾)的大小仍不能满足要求，则应返回链首，继续查找；(循环)
       * 优点：空闲分区分布更均匀，减少了查找开销；
       * 缺点：缺乏大的空闲分区；
     * 最佳适应算法(Best Fit, BF)
       * “最佳”：每次为作业分配内存时，总是把能满足要求、又是最小的空闲分区分配给作业；
       * 要求：将所有的空闲分区以从小到大的顺序形成一空闲分区链；(加速寻找)
       * 做法：第一次找到的能满足要求的空闲分区必然是最佳的；
       * 宏观上不一定是“最佳”：每次分配后所切割下来的剩余部分总是最小的，存储器中会有很多碎片
     * 最坏适应算法(Worst Fit, WF)
       * 要求：将所有空闲分区按照从大到小的顺序形成一个空闲分区链；
       * 做法：与BF正好相反，每次总是挑选最大的空闲区，从中分割一部分存储空间给作业使用；
       * 优点：
         * 使剩下的空闲区不至于太小，产生碎片的可能性最小，对中小作业有利；
         * 查找效率高(只要看第一个分区能否满足要求)；
       * 缺点：缺乏大空闲区；

   * 基于**索引搜索**的动态分区分配算法：
     * 问题：当系统很大时，系统中的内存分区可能会很多，相应的空闲分区链就可能很长，这时采用顺序搜索分区方法可能会很慢；
     * 解决办法：采用基于索引搜索的动态分区分配算法；
     * 目的：提高搜索空闲分区的速度；
     * 分类：快速适应算法、伙伴系统、哈希算法
       * 快速适应算法(Quick Fit)：
         * 做法：
           * 将空闲分区根据进程常用的空间大小进行分类，建立管理索引表，每个表项对应一类；
           * 根据进程长度，从索引表中去寻找能容纳它的最小空闲分区链表；
           * 从链表中取下第一块进行分配，不再分割；
         * 优点：
           * 不会对分区产生任何分割，能保留大分区，不会产生内存碎片；
           * 查找效率高；
         * 缺点：算法复杂，系统开销大；
       * 伙伴系统(Buddy System)：
         * 规定：无论是已分配分区还是空闲分区，其大小均为2的k次幂；
         * 做法：(参考书)
             * 查找；
             * 划分；
             * 合并；
       * 哈希算法：
         * 思想：利用哈希快速查找的特点，构建一张以空闲分区为关键字的哈希表，该表的每一个表项纪录了一个对应的空闲分区链表表头指针；
         * 做法：(参考书)

4. 分配分区的操作：

   * 分配内存：
     * 说明：
       * u.size：请求的分区大小；
       * m.size：表中每个空闲分区的大小；
       * size：事先规定的不再分割的剩余分区的大小
     * 步骤：
       * 若m.size - u.size <= size，说明多余部分太小，不可再分割，将整个分区分配给请求者；
       * 否则，从该分区中按请求的大小划分出一块内存空间分配出去，余下的部分仍留在空闲分区链(表)中；
       * 然后将分配区的首地址返回给调用者；
   * 回收内存：
     * 当进程运行完毕释放内存时，系统根据回收区的首地址，从空闲分区链表中找到相应的插入点，此时可能有四种情况：
       * 回收区与插入点的前一个空闲分区F1相邻接：
       * 回收区与插入点的后一个空闲分区F2相邻接：
       * 回收区与插入点的前后两个空闲分区F1、F2都相邻接：
       * 回收区与插入点的前后两个空闲分区F1、F2都相不邻接：



### 4.3.4 动态可重定位分区分配

1. 紧凑：

   * 连续分配方式的特点：一个进程必须被装入一片连续的内存空间；
   * 问题：当OS运行一段时间后，内存空间被分割成很多小分区，缺乏大的空闲分区。即使这些分散的小分区的总容量比进程需求的要大，但是由于不相邻接，所以进程无法被装入内存；
   * 解决方法：紧凑(将内存中所有作业移动，使它们互相邻接)
   * 紧凑的缺点：每次紧凑后，都必须重定位，开销大；

2. 动态重定位：

   * 做法：逻辑地址到物理地址的变换是在程序执行期间进行；

   * 重定位寄存器：用来存放程序在内存中的起始地址；

     (程序执行时，将相对地址与重定位寄存器中的地址相加，即可得到真正要访问的内存地址)

   * 紧凑：只需要将程序在内存中新的起始地址去置换原来的起始地址即可；

3. 动态重定位分区分配算法：

   * 与动态分区分配算法基本相同，只是增加了紧凑功能；



## 4.4 离散分配

1. 思想：将一个进程直接分散地装入到许多不相邻接的分区中，可充分利用存储空间，无须再进行“紧凑”；
2. 方式：(根据所分配地址空间的基本单位不同划分)
   * 分页存储管理：每页大小固定；
   * 分段存储管理：每段大小不固定；
   * 段页存储管理：分页与分段结合；



### 4.4.1 分页存储管理

1. 基本方法：
   * 页面和物理块：
     * 做法：将进程的逻辑空间和内存的物理空间，都划分为相同大小的若干页；
     * 页面大小：通常1KB - 8KB；
   * 地址结构：
     * 两部分：页号、偏移量；
     * 举例：(参考书)
   * 页表：
     * 目的：为保证进程正确运行(能在内存中找到每个页面对应的物理块)，系统为每个进程建立了一张页面映像表，简称页表；
     * 内容：
       * 相应页在内存中对应的物理块号；
       * 存取控制字段；(用于对该存取块中的内容加以保护)
     * 作用：实现从页号到物理块号的地址映射；

2. 地址变换机构：
   * 目的：将用户地址空间的逻辑地址转换为内存空间中的物理地址；

   * 基本任务：实现从逻辑地址到物理地址的转换；

   * 实际任务：将逻辑地址中的页号转换为内存中的物理块号；

       ​					(页内地址和物理地址是一一对应的，无需转换)

   * 途径：借助页表；

   * 分类：

     * 基本的地址变换机构

       * 页表寄存器PTR(Page Table Register)：存放页表在内存中的始址和页表长度；

       * 地址变换过程：
   
         * 将逻辑地址分为页号和页内地址；
         * 比较页号与页表长度，检查是否越界。若越界，中断；若没越界，进行下一步；
      * 将页表始址与页号和页面大小的乘积相加，找到该表项在页表中的位置，从中得到该页的物理块号；
        
  * 由物理块号和页内地址访问对应的内存单元；
         
    * 特点：
     
      * 由于页表存放在内存中，CPU每存取一个数据时，需要两次访问内存，效率降低；
     
        (访问页表、访问实际物理地址)
   
  * 具有快表的地址变换机构：(快表相当于缓存)
   
    * 联想寄存器(Associative Memory)：又称快表，用于存放当前访问的页表项；(与Cache类似)
     
      (一个具有并行查找能力的特殊高速缓冲寄存器)
     
    * 作用：提高地址变换速度；
   
   * 访问内存的有效时间
   
  * 有效访问时间EAT(Effective Access Time)：从进程发出指定逻辑地址的访问请求，经过地址变换，到在内存中找到对应的实际物理地址单元并取出数据，所要花费的总时间；
     
     * 引入快表，使得EAT明显减少；

3. 两级和多级页表：

   * 问题：在支持非常大逻辑空间的OS中，页表的表项很多，需要占用相当大的、连续的内存空间；
   * 解决方案：
     * 对于页表所需的内存空间，采用离散分配方式(两级或多级页表)；(连续)
     * 只将当前需要的部分页表调入内存，其余页表仍然驻留在磁盘上；(相当大)
   * 两级页表：
     * 基本原理：将页表占据的内存空间进行分页；
     * 逻辑机构：外部页表、内部页表；
     * 地址结构：外层页号、外层页内地址、页内地址；
   * 多级页表：
     * 若两级页表的表项还是很多，占据连续内存空间还是很大，可继续添加外层页表；

4. 反置页表：

   * 目的：减少页表占用的内存空间；

   * 基本原理：为每个物理块设置一个页表项，并将它们按照物理块的编号排序；

     (对于具有64M内存的机器，若页面大小为4KB，则反置页表只占64KB内存)

   * 表项内容：页号、所属进程标识符；

   * 搜索算法：Hash算法



### 4.4.2 分段存储管理

1. 目的：满足程序员在编程和使用上多方面的要求；

   (前述所有的内存管理方式，其主要目的都是提高内存利用率)

2. 待满足的需要：(以逻辑单位为基础，而非物理单位)

   * 方便编程；
   * 信息共享；
   * 信息保护；
   * 动态增长；
   * 动态链接；

3. 基本原理

   * 分段：作业的地址空间按照逻辑关系被划分若干段，每段的逻辑地址由段号和段内地址组成；

   * 内存分配方式：

     在分段式存储管理系统中，为每个段分配一个连续的分区，各个段可以离散地装入内存中的不同分区中(而在动态分区分配中，系统为整个进程分配一个连续的内存空间)；

   * 段表：

     * 作用：实现从逻辑段到物理内存区的映射；

     * 表项：段号、段长、基址(该段在内存中的起始地址)；

   * 地址变换机构：

     * 变换过程：(参考书 P.148 图4-20)
     * 特点：需要两次访问内存(访问段表、访问实际物理地址)

4. 突出优点：易于实现段的共享和保护



### 4.4.3 分页与分段的异同点

1. 相同点：
   * 都采用离散分配方式；
   * 都通过地址映射机构来实现地址转换；
2. 不同点：
   * 页是信息的物理单位，段是信息的逻辑单位；
   * 页的大小固定且由系统决定，段的大小不固定且由用户决定；
   * 分页系统中，用户程序的地址空间是一维的；分段系统中，用户程序的地址空间是二维的(段名+段内地址)



### 4.4.4 段页式存储管理

1. 基本原理：

   * 地址划分：先将用户程序划分为若干个段，然后把每个段分成若干页；
   * 地址结构：段号 + 段内页号 + 页内地址
   * 数据结构：
     * 段表：存放页表始址和页表长度
     * 页表：页号 + 物理块号

2. 地址变换过程：

   (参考书P.151 图4-24、4-25)

3. 特点：

   * 在段页式系统中，为了获得一条指令或数据，需要三次访问内存

     (访问段表，访问页表，访问实际物理地址)



## 4.5 对换(Swapping)

### 4.5.1 对换

1. 问题：内存中某进程因为某事件而阻塞，但却占用大量内存空间，导致其它进程阻塞；

2. 对换：把内存中被阻塞的进程换出到外存上，以腾出内存空间，把外存中就绪状态的进程换入；

   ​	(Suspend & Active ：活动阻塞—静止阻塞；静止就绪—活动就绪)

3. 对换的目的：提高处理机利用率和系统的吞吐量；

4. 对换的类型：

   - 整体对换：以进程为单位，又称进程对换(处理机的中级调度)；
   - 部分对换：以进程的一个“页面”或“分段”为单位，又称为页面对换或分段对换(其目的是支持虚拟存储)；



### 4.5.2 对换空间的管理

1. 在具有对换功能的OS中，将磁盘分为文件区和对换区：
   - 文件区：
     - 特点：文件长时间驻留在外存，访问频率低；
     - 目标：主要是提高存储空间利用率，然后才是提高对文件的访问速度；
     - 方式：离散分配；
   - 对换区：
     - 特点：进程短时间驻留在对换区，访问频率高；
     - 目标：主要是提高进程换入和换出的速度，然后才是提高存储空间利用率；
     - 方式：连续分配；
2. 对换区的数据结构：与内存的动态分区分配方式中用的数据结构类似；
3. 对换空间的分配与回收：与连续分配内存中的方法类似；



### 4.5.3 对换过程

1. 进程的换出(Suspend) (只能换出非共享的程序与数据段)
2. 进程的换入(Active)

